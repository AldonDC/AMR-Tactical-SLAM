# AMR 2026: Framework Avanzado de SLAM LiDAR-RTK

Sistema profesional de **NavegaciÃ³n y Mapeo (SLAM)** de alta precisiÃ³n para robots autÃ³nomos, optimizado para **ROS 2 Humble**. Integra nubes de puntos 3D con posicionamiento RTK-GPS centimÃ©trico.

---

## ğŸ› ï¸ Stack TecnolÃ³gico

![ROS 2](https://img.shields.io/badge/ROS2-Humble-blue?style=for-the-badge&logo=ros)
![Python](https://img.shields.io/badge/Python-3.10-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Ubuntu](https://img.shields.io/badge/Ubuntu-22.04-E95420?style=for-the-badge&logo=ubuntu&logoColor=white)
![Open3D](https://img.shields.io/badge/Open3D-3D_Engine-orange?style=for-the-badge)

---

## ğŸ§  Bases AlgorÃ­tmicas

### 1. Auto-CalibraciÃ³n CinemÃ¡tica
Elimina la necesidad de medir manualmente la posiciÃ³n del sensor. El sistema correlaciona el vector de movimiento del RTK con la distribuciÃ³n de puntos del LiDAR:
*   **CÃ¡lculo**: Se analizan los primeros 15 keyframes para resolver el desfase angular $\Delta\psi$ entre el heading del GPS $(\theta_{RTK})$ y el eje principal del LiDAR $(\theta_{LiDAR})$:
    $$\Delta\psi = \arg\min \sum | \vec{v}_{RTK} - \mathbf{R}(\theta) \cdot \vec{d}_{LiDAR} |$$

### 2. ClasificaciÃ³n SemÃ¡ntica GeomÃ©trica
El SLAM identifica objetos sin necesidad de IA pesada, usando descriptores de forma:
*   **Postes/Infraestructura**: RelaciÃ³n altura/ancho $> 2.2$ y ancho $< 0.6m$.
*   **VegetaciÃ³n**: Clusters irregulares detectados mediante **DBSCAN** ($eps=0.4, min\_pts=12$).
*   **Estructuras**: Planos anchos con superficie $> 4.0m$.

### 3. FusiÃ³n GeodÃ©sica (WGS84 â” ENU)
Proyecta las coordenadas globales $(\phi, \lambda, h)$ al plano local Cartesiano $(e, n, u)$ usando el elipsoide WGS84, aplicando una **correcciÃ³n de brazo de palanca (Lever-Arm)** para compensar la distancia fÃ­sica entre la antena y el centro del robot.

---

## ğŸš€ Pipeline de OperaciÃ³n

1.  **Fase V1 (Mapeo)**: ConstrucciÃ³n de mapa HD. Los puntos se integran solo si el robot se mueve $> 3m$ para evitar saturaciÃ³n.
2.  **Cierre de Bucle**: Al detectar que el robot regresa al origen (radio $< 15m$) despuÃ©s de recorrer $> 80m$, el mapa se congela y se guarda en `.ply`.
3.  **Fase V2 (LocalizaciÃ³n)**: El sistema cambia a modo estÃ¡tico para navegaciÃ³n pura sobre el mapa generado, eliminando derivas.

---

## ğŸ›°ï¸ Mission Control (HUD TÃ¡ctico)
Interfaz en **Python** que funciona como centro de mando:
*   **Mosaico Satelital**: Descarga en tiempo real mapas de ESRI (Zoom 18).
*   **TelemetrÃ­a Proyectada**: ConversiÃ³n inversa de ENU a LLA para alinear la trayectoria del robot con el satÃ©lite.
*   **HUD**: Muestra velocidad (km/h), rumbo y fase actual de la misiÃ³n.

---

## ğŸ Estado del Proyecto: CONCLUIDO âœ…

*   [x] FusiÃ³n LiDAR-RTK robusta.
*   [x] Motor de auto-calibraciÃ³n funcional.
*   [x] ClasificaciÃ³n de objetos en tiempo real.
*   [x] Centro de mando satelital operativo.

---

## ğŸ’¾ InstalaciÃ³n RÃ¡pida
```bash
# Dependencias
pip install numpy open3d scipy matplotlib requests Pillow

# CompilaciÃ³n
cd amr_2026_research_m&l
colcon build --symlink-install
source install/setup.bash

# Lanzamiento Profesional
ros2 launch lidar_rtk_slam rtk_direct_slam.launch.py
```

---
**Desarrollado por**: Alfonso | **DivisiÃ³n**: AMR 2026 Research ğŸï¸ğŸ›°ï¸ğŸ¦¾
